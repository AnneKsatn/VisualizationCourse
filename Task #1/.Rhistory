run = rep(1:random_trials, each = possible_clusts)
)
# IG(1) = 0, IG(possible_clusts) = 1
# cut_limits <- c(2, possible_clusts - 1)
## writing results to data frames in order to later plot them and calculate various statistics
data_igs <-
data_frame(
k = actual_clusters,
igain = igs
)
## a list with two data frames, for original and shuffled data
list_out <-
list(
# observed data
data_igs = data_igs,
# random data
data_rtrials = data_rtrials,
# useful for calculating ideal splits
class_labels = classes
# determines fot color on the watermelon plot later
)
return(list_out)
}
ideal_ig_trajectory <- function(class_labels) {
# entropy for a single cluster
entropy <- function(labels) {
## an obvious case
if (length(labels) == 1) return(0)
labels %>%
table() %>%
## there shouldn't be zeros in the table
divide_by(sum(.)) %>%
inset(. == 0, 1) %>%
## entropy is measured in bits
{-1*.*log2(.)} %>%
sum()
}
# order in which the classes will be excluded; ties don't matter
class_freqs <-
class_labels %>%
table() %>%
sort(decreasing = TRUE) %>%
# frequencies
divide_by(sum(.))
# base entropy
H0 <- entropy(class_labels)
# a vector containing ideally-splitted classes' entropies
max_ig_trajectory <-
c(0, rep(1, length(class_labels) - 1)) %>%
set_names(
c(
# root
"root",
# removed class
names(class_freqs),
# additional stuff
rep("", length(class_labels) - length(class_freqs) - 1)
)
)
levels_excluded <- character(0)
for (level in names(class_freqs)[1:(length(class_freqs) - 1)]) {
levels_excluded %<>% c(level)
max_ig_trajectory[level] <- 1 - class_freqs[level]*entropy(class_labels[!class_labels %in% levels_excluded])
}
# 1 if everything has been grouped correctly
names(max_ig_trajectory)[1:length(class_freqs) + 1] %<>% str_c("removed ", .)
return(max_ig_trajectory)
}
## a separate function to obtain the criterion value
## takes an output of evaluate_hclust
watermelon_area <- function(ig_datalist) {
data_rtrials <- ig_datalist$data_rtrials
data_igs <- ig_datalist$data_igs
data_classes <- ig_datalist$class_labels
cut_limits <- c(1, max(data_rtrials$k))
rquantiles <-
data_rtrials %>%
group_by(k) %>%
dplyr::summarise(igain = quantile(igain, 0.95)) %$%
igain
ideal_traj <- ideal_ig_trajectory(data_classes)
## histogram-like estimate of total area,
## negative area also counts!
area <- sum(data_igs$igain - rquantiles) / sum(ideal_traj - rquantiles)
return(area)
}
watermelon_plot <-
function(
ig_datalist,
# an output of evaluateHclust
plot_name = 'Watermelon plot',
# plot name displayed in the heading
bootstrap_ci = TRUE,
# include bootstrap 95%CI? will take some time to calculate
bootstrap_runs = 500,
# how much bootstrap trials should be performed?
dots_percent = 0.6,
# percent of dots shown on the plot for faster plotting
seed = 451,
# random seed
show_legend = TRUE
) {
require(easypackages)
suppressMessages(libraries('tidyr', 'dplyr', 'forcats', 'ggplot2', 'magrittr', 'stringr'))
data_igs <-
ig_datalist$data_igs %>%
mutate(`Curve type` = 'Observed data')
data_rtrials <- ig_datalist$data_rtrials
data_ideal <-
data_frame(
k = 1:nrow(data_igs),
igain = ideal_ig_trajectory(ig_datalist$class_labels),
`Curve type` = 'Ideal class separation'
)
data_criterion <-
data_rtrials %>%
group_by(k) %>%
dplyr::summarise(igain = quantile(igain, 0.95)) %>%
mutate(`Curve type` = '95% of random trials') %>%
bind_rows(., data_igs, data_ideal) %>%
mutate(`Curve type` = factor(`Curve type`))
## used to draw the area
## transformed to satisfy row-wise ymin / ymax easthetics format
data_area <-
data_criterion %>%
filter(`Curve type` %in% c("Observed data", "95% of random trials")) %>%
tidyr::spread(`Curve type`, igain) %>%
mutate(area_sign = ifelse(`Observed data` > `95% of random trials` | `95% of random trials` == 1, '+', '-') %>% factor() %>% fct_rev()) # %>%
# if this isn't done this will result in a geom_ribbon stretching glitch
# filter(`95% of random trials` != `Observed data`)
## for faster plotting
if (dots_percent != 1) {
## randomly sampling the dots
## the plot will look more chaotic, the outliers appear quite variable at each k
set.seed(seed)
data_rtrials %<>% filter(run %in% 1:floor(max(run)*dots_percent))
}
area <- watermelon_area(ig_datalist)
## dot size should be dependent on the number of samples (the graph becomes smaller)
## a heuristic
minor_dot_size <- 1.4 * (4.5/sqrt(nrow(data_igs)))
major_dot_size <- 2.65 * (4.5/sqrt(nrow(data_igs)))
# a stringie which contains confidence interval
boot_string <- ci_string <- character(0)
if (bootstrap_ci) {
# reuqires bootstrap.R to be sourced first!
wm_bootstrap <-
watermelon_bootstrap(
ig_datalist = ig_datalist,
step = -1,
bootstrap_trials = bootstrap_runs,
seed = seed
)
wm_ci_df <- watermelon_area_ci(wm_bootstrap)
wm_ci <- round(c(wm_ci_df$lower_bound, wm_ci_df$upper_bound), 4)
# pieces of information that'd be plotted
ci_string <- str_c('\n95% bootstrap CI: [', wm_ci[1], '; ', wm_ci[2], ']')
boot_string <- str_c('\nNumber of bootstrap resamples = ', bootstrap_runs)
}
main_colors <-
c(
'Ideal class separation' = 'dodgerblue3',
'Observed data' = 'forestgreen',
'95% of random trials' = 'firebrick2'
)
plot_ig <-
ggplot(data_igs, aes(x = k, y = igain)) +
geom_abline(
slope = 1 / (max(data_igs$k) - 1),
intercept = -1 / (max(data_igs$k) - 1),
color = 'darkgrey',
size = 2.5
) +
geom_jitter(
data = data_rtrials,
mapping = aes(x = k, y = igain),
color = 'firebrick2',
alpha = 0.07,
size = major_dot_size,
width = 0.15,
height = 0
) +
geom_line(
data = data_criterion,
aes(x = k, y = igain, color = `Curve type`),
size = 2.0,
inherit.aes = FALSE
) +
scale_color_manual(values = main_colors) +
geom_point(shape = 16, size = minor_dot_size, color = 'black') +
theme(
legend.position = c(0.8, 0.2),
legend.background = element_rect(linetype = 'solid', color = 'black', fill = 'lightgrey'),
panel.background = element_blank(),
panel.grid.major = element_line(color = 'lightgrey'),
panel.grid.minor = element_line(color = 'lightgrey')
) +
# guides(color = guide_legend(override.aes = list(shape = c(5, 5, 5)), reverse = FALSE)) +
labs(x = 'Dendrogram depth',
y = 'Normalized Information Gain',
title = str_c(
plot_name,
'\n',
str_c('Statistically significant area = ',
round(area, 4),
' units; ',
ci_string)
),
caption = str_c(
'Number of randomizations = ', max(data_rtrials$run),
# either empty or contains info on a number of bootstrap trials conducted
boot_string,
'\nSeed = ', seed
)
)
if(!show_legend) plot_ig <- plot_ig + guides(color = FALSE)
plot_ig
}
# writes the results in separate txt files
write_wm <- function(wm, path) {
field_names <- c("data_igs", "data_rtrials", "class_labels")
for (field_name in names(wm)) {
write_tsv(tbl_df(wm[[field_name]]), str_c(path, field_name, ".txt"))
}
}
# reads the results from a folder
read_wm <- function(path) {
wm_obj <- list()
field_names <- c("data_igs", "data_rtrials", "class_labels")
for (field_name in field_names) {
wm_obj[[field_name]] <- read_tsv(str_c(path, field_name, ".txt"), progress = FALSE)
}
# should be a char vector rather than df
wm_obj[["class_labels"]] %<>% extract2(1)
return(wm_obj)
}
watermelon_on_grid <- function(
data_mat,
classes,
feature_sets = list(all_features = rownames(data_mat)),
# all methods with monotonously increasing distance
hc_methods = c("single", "complete", "average", "mcquitty", "ward.D", "ward.D2"),
# how much random trials in each case?
random_trials = 300,
# how much bootstrap trials for CI calculation?
bootstrap_trials = 500,
# display progress bar?
progress = TRUE,
# drop a warning if the maxima is non-significant?
verbose = TRUE,
# seed for the clusterings
seed = 451
) {
if (progress) {
pb <-
progress_bar$new(
total = length(hc_methods) * length(feature_sets),
format = "Exploring grid: [:bar] :percent Time left::eta"
)
}
# holds all the results
wm_summary <-
data_frame(
# all combos of methods and feature sets
hc_method = rep(hc_methods, each = length(feature_sets)),
feature_set = rep(names(feature_sets), length(hc_methods)),
# metric and CI
wm_area = 0,
wm_a_upper = 0,
wm_a_lower = 0,
# other things
random_trials = random_trials,
bootstrap_trials = bootstrap_trials
)
for (hc_method in hc_methods) {
for(fset_name in names(feature_sets)) {
fset <- feature_sets[[fset_name]]
# fast distance; restoring lost dimnames manually
# plugging it into the clustering
data_dist <- data_mat[fset, , drop = FALSE] %>% t() %>% parDist() %>% data.matrix()
dimnames(data_dist) <- list(colnames(data_mat), colnames(data_mat))
data_dist %<>% as.dist()
data_hc <- hclust(data_dist, method = hc_method)
wm <-
evaluate_hclust(
data_hc,
classes = classes,
random_trials = random_trials,
# slightly different for each run
seed = seed + which(hc_method == hc_methods) + which(fset_name == names(feature_sets)),
progress = FALSE
)
wm_boot <- watermelon_bootstrap(wm, step = -1, bootstrap_trials = bootstrap_trials)
wm_boot_ci <- watermelon_area_ci(wm_boot)
df_mask <-
wm_summary[["hc_method"]] == hc_method &
wm_summary[["feature_set"]] == fset_name
wm_summary[df_mask, ][["wm_area"]] <- watermelon_area(wm)
wm_summary[df_mask, ][["wm_a_upper"]] <- wm_boot_ci[["upper_bound"]]
wm_summary[df_mask, ][["wm_a_lower"]] <- wm_boot_ci[["lower_bound"]]
if(progress) pb$tick()
}
}
# drops a warning if non-significant maxima (CI overlaps with any other point)
if (verbose) {
wm_max_i <- which.max(wm_summary[["wm_area"]])
wm_max_lower <- wm_summary[wm_max_i, ][["wm_a_lower"]]
wm_rest_upper <- max(wm_summary[-wm_max_i, ][["wm_a_upper"]])
# if upper bound of any CI criscrosses maxima's lower bound
if (wm_rest_upper >= wm_max_lower) warning("Non-significant maxima produced!")
}
return(wm_summary)
}
plot_grid_result <- function(grid_result, n_best = 10, size = 1) { #, across = c("hc_method", "feature_set")) {
main_color <- "deepskyblue4"
if (n_best < nrow(grid_result)) message(str_c("Showing only ", n_best, " best results of total ",  nrow(grid_result)))
grid_result %<>%
mutate(
trial = str_c(hc_method, "\n", feature_set) %>% forcats::fct_reorder(wm_area)
) %>%
# somethimes there's too much combinations
top_n(n_best, wm_area)
ggplot(grid_result, aes(y = trial, x = wm_area, xmin = wm_a_lower, xmax = wm_a_upper, color = hc_method)) +
geom_point(size = size) +
geom_errorbarh(size = size, height = 0.2) +
geom_vline(xintercept  = c(0, 1), color = c("red", "forestgreen")) +
labs(x = "Watermelon area", y = "Method and feature set")
}
heatmap_grid_result <- function(grid_result) {
grid_result %<>%
mutate(
wm_area_best = ifelse(wm_area >= 0.75 * max(wm_area), round(wm_area, 3), "")
)
ggplot(grid_result, aes(x = hc_method, y = feature_set, fill = wm_area)) +
geom_tile() +
geom_text(aes(label = wm_area_best)) +
scale_fill_gradientn(
name = "Watermelon area",
colours = RColorBrewer::brewer.pal(6, "YlOrRd"),
limits = 0:1,
na.value = "grey50"
) +
theme(
legend.position = "bottom"
) +
guides(fill = guide_colorbar(title.position = "left", barwidth = 13, barheight = 1)) +
labs(x = "Clustering method", y = "Feature set")
}
prefix = "/mnt/disk1/New_archive/Sh_SEQC_GDC/"
Ps = c('571', '10558', '11154', 'AGL', '75')
NP = length(Ps)
Qs = c("0", "1")
NQ = length(Qs)
methods = array("XYZXYZ", dim = c(NP*NQ))
for ( nq in 1:NQ ) {
for ( np in 1:NP ) {
methods[np + (nq-1)*NP] = paste(Ps[np], Qs[nq], sep = "_")
}
}
M = length(methods)
bar_row_labels = c("Platform", "Samples")
LAB = c(bar_row_labels, "Ratio")
title_for_method = methods
WM = array(dim=c(25,2*M))
for ( iii in 1:25 ) {
if (iii < 10 ) IFN = paste(prefix, "/reduced/meta_0", toString(iii), ".csv", sep = "")
if (iii >= 10 ) IFN = paste(prefix, "/reduced/meta_", toString(iii), ".csv", sep = "")
meta = read.table(IFN, header = TRUE, sep = ",")
NS = nrow(meta)
D = as.vector(meta[,2])
P = as.vector(meta[,3])
S = as.vector(meta[,1])
UD = unique(D)
UP = unique(P)
NUD = length(UD)
CT_D = 1:NUD
t_rgb = col2rgb("red")
t_hsv = rgb2hsv(t_rgb)
for ( nud in 1:NUD ) {
t_hsv[1] = (nud-1)/(NUD+1);
CT_D[nud] = hsv(t_hsv[1],1,t_hsv[3]);
}
NUP = length(UP)
CT_P = 1:NUP
t_rgb = col2rgb("red")
t_hsv = rgb2hsv(t_rgb)
for ( nup in 1:NUP ) {
t_hsv[1] = (nup-1)/(NUP+4);
CT_P[nup] = hsv(t_hsv[1],0.5,t_hsv[3]);
}
CD = array(dim=c(NS))
CP = array(dim=c(NS))
for ( ns in 1:NS ) {
d = D[ns]
index = which (d == UD)
CD[ns] = CT_D[index]
p = P[ns]
index = which (p == UP)
CP[ns] = CT_P[index]
}
for ( m in 1:M )  {
print (m)
if (iii < 10 ) IFN = paste(prefix, "reduced/Sh_", methods[m], "_0", toString(iii), ".csv", sep = "")
if (iii >= 10 ) IFN = paste(prefix, "reduced/Sh_", methods[m], "_", toString(iii), ".csv", sep = "")
mas_all = read.table(IFN, header = TRUE, sep = ",")
mas_all = as.matrix(mas_all)
mas_all = log10(mas_all+1)
mas_all = t(mas_all)
DDD = dist(mas_all)
par(cex.axis = 1)
hc = hclust(DDD)
hcd = as.dendrogram (hc)
dend_labels = hcd %>% labels
nlabels = length(dend_labels)
bar_color_cancer = array("XYZXYZ", dim = c(nlabels))
bar_color_platform = array("XYZXYZ", dim = c(nlabels))
for ( ilabel in 1:nlabels ) {
sample = dend_labels[ilabel]
index = which ( sample == S )
bar_color_cancer[ilabel] = CD[index]
bar_color_platform[ilabel] = CP[index]
dend_labels[ilabel]=""
}
if ( iii < 10 ) GFN = paste(prefix, "dend/Sh_", methods[m], "_0", toString(iii),  ".ps", sep = "")
if ( iii >= 10 ) GFN = paste(prefix, "dend/Sh_", methods[m], "_", toString(iii),  ".ps", sep = "")
postscript(file=GFN)
par(cex.axis = 1.5)
par(cex.main = 2)
hcd %>% set("labels", dend_labels) %>% plot()
par(cex.lab = 1.5)
par(mar = c(8,4,4,5)+.1)
title(main = title_for_method[m], sub = "", ylab = "Distance")
bar_colors = cbind(bar_color_platform, bar_color_cancer)
colored_bars(
colors=bar_colors,
dend=hcd,
sort_by_labels_order = FALSE,
rowLabels = bar_row_labels,
cex.rowLabels = 1.5,
y_scale = bar_y_scale(hcd),
y_shift = -bar_y_scale(hcd)
)
dev.off()
res1 = evaluate_hclust(tree=hc,classes=D,random_trials = 25)
res10 = watermelon_area(res1)
WM[iii,m] = res10
res2 = evaluate_hclust(tree=hc,classes=P,random_trials = 25)
res20 = watermelon_area(res2)
WM[iii,m+M] = res20
}
}
CN = array("XYZXYZ",dim = c(2*M))
CN1 = array("XYZXYZ",dim = c(2*M))
for (kkk in 1:3) {
for ( m in 1:M ) {
if (kkk < 3) CN[m + (kkk-1)*M] = paste (methods[m], bar_row_labels[kkk], sep = "_")
CN1[m + (kkk-1)*M] = paste (methods[m], LAB[kkk], sep = "_")
}
}
OFN = paste(prefix, "/dend/WM10.csv", sep = "")
write.table(WM,OFN,col.names = CN, row.names = FALSE, sep=",")
WM0 = array(dim=c(25,M))
for ( iii in 1:25 ){
for ( m in 1:M ) {
WM0[iii,m] = (WM[iii,m]*NUD) / (WM[iii,m+M]*NUP)
}
}
WM1 = cbind(WM,WM0)
OFN = paste(prefix, "/dend/WM101.csv", sep = "")
write.table(WM1,OFN,col.names = CN1, row.names = FALSE, sep=",")
WM1_ = read.table(OFN, header = TRUE, sep=",")
WM0_ = WM1_[,-(1:6)]
GFN = paste(prefix, "/dend/Ratio10.png", sep = "")
png(file=GFN)
par(cex.axis=1.5, cex.lab=1.5)
boxplot (WM0)
dev.off()
GFN = paste(prefix, "/dend/legend10.ps", sep = "")
postscript(file=GFN)
plot.new( )
legend("topleft", legend = UD, fill = CT_D, border = CT_D, bty = "n", cex = 1.9)
legend("topright", legend = UP, fill = CT_P, border = CT_P, bty = "n", cex = 3)
dev.off()
write.table(d, file='IQGAP_expression.txt')
d <- read.table("IQGAP_expression.txt")
d <- read.table("C:\Users\Anna_\Documents\GitHub\VisualizationCourse\Task #1\IQGAP_expression.txt")
d <- read.table("C:/Users/Anna_/Documents/GitHub/VisualizationCourse/Task #1/IQGAP_expression.txt")
View(d)
getwd()
d <- read.table(getwd() + "GitHub/VisualizationCourse/Task #1/IQGAP_expression.txt")
getwd()
setwd()
setwd("C:/Users/Anna_/Documents/GitHub/VisualizationCourse/Task #1")
getwd()
d <- read.table("IQGAP_expression.txt",)
d <- read.table("IQGAP_expression.txt", header=TRUE)
View(d)
d <- read.table("IQGAP_expression.txt", header=TRUE, col.names = 1)
d <- read.table("IQGAP_expression.txt", header=TRUE, row.names = 1)
View(d)
data <- transpose(d)
data  = transpose(d, keep.names = "col", make.names = "col0")
install.packages("data.table")
data  = transpose(d, keep.names = "col", make.names = "col0")
data  = data.table.transpose(d, keep.names = "col", make.names = "col0")
ll = list(1:5, 6:8)
transpose(ll)
setDT(transpose(ll, fill=0))[]
DT = data.table(x=1:5, y=6:10)
transpose(DT)
install.packages("data")
install.packages("data")
